{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e6b7ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22d14423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths\n",
    "RAW_DATA_DIR = Path(\"data/raw_data\")\n",
    "CLEANED_DATA_DIR = Path(\"data/cleaned_data\")\n",
    "FEATURES_DIR = Path(\"data/features\")\n",
    "MODELS_DIR = Path(\"models\")\n",
    "\n",
    "for path in [CLEANED_DATA_DIR, FEATURES_DIR, MODELS_DIR]:\n",
    "    path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8318cf3a",
   "metadata": {},
   "source": [
    "## LORIN et al. (2025) Dataset Processing\n",
    "### Step 1: Cleaning with readable feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad8439d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lorin2025Processor:\n",
    "    \"\"\"Processes Lorin et al. (2025) dataset for personality-based capability prediction\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def process():\n",
    "        print(\"Processing Lorin 2025 Dataset...\")\n",
    "        \n",
    "        df = pd.read_csv(RAW_DATA_DIR / \"phishing_lorin_2025.csv\")\n",
    "        print(f\"Raw data: {len(df)} rows, {len(df.columns)} columns\")\n",
    "        \n",
    "        # Feature mapping based on the provided specification\n",
    "        features = {\n",
    "            # === DEMOGRAPHICS & BACKGROUND ===\n",
    "            'age_category': 'dem_age',\n",
    "            'education_level': 'dem_edu', \n",
    "            'it_experience': 'dem_it',\n",
    "            'email_frequency': 'mailboxfrequency',\n",
    "            'security_training_prior': 'securitytraining',\n",
    "            \n",
    "            # === BIG FIVE PERSONALITY TRAITS (COMPOSITES) ===\n",
    "            'personality_extraversion': 'bfi_extraversion',\n",
    "            'personality_agreeableness': 'bfi_agreeableness', \n",
    "            'personality_conscientiousness': 'bfi_conscientiousness',\n",
    "            'personality_neuroticism': 'bfi_neuroticism',\n",
    "            'personality_openness': 'bfi_openness',\n",
    "            \n",
    "            # === PRE-TRAINING SECURITY ATTITUDES ===\n",
    "            'security_engagement': 'pre.sa13_engagement',\n",
    "            'security_attentiveness': 'pre.sa13_attentiveness', \n",
    "            'security_resistance': 'pre.sa13_resistance',\n",
    "            'security_concern': 'pre.sa13_concernedness',\n",
    "            'security_attitude_total': 'pre.sa13_total',\n",
    "            \n",
    "            # === BASELINE CAPABILITIES ===\n",
    "            'knowledge_total': 'knowledge_total_pre',\n",
    "            'proficiency': 'proficiency_pre',\n",
    "            \n",
    "            # === TARGET VARIABLES ===\n",
    "            'class_phish_accuracy': 'class_phish_accuracy_pre',\n",
    "            'class_nophish_accuracy': 'class_nophish_accuracy_pre',\n",
    "        }\n",
    "        \n",
    "        # Create cleaned dataframe\n",
    "        cleaned = pd.DataFrame()\n",
    "        missing_cols = []\n",
    "        \n",
    "        for new_col, old_col in features.items():\n",
    "            if old_col in df.columns:\n",
    "                cleaned[new_col] = df[old_col]\n",
    "            else:\n",
    "                print(f\"Warning: Column '{old_col}' not found, setting '{new_col}' to NaN\")\n",
    "                cleaned[new_col] = np.nan\n",
    "                missing_cols.append(old_col)\n",
    "        \n",
    "        # Data quality filters\n",
    "        initial_count = len(cleaned)\n",
    "        \n",
    "        # Filter 1: Remove rows with missing target variables\n",
    "        target_cols = ['class_phish_accuracy', 'class_nophish_accuracy']\n",
    "        cleaned = cleaned.dropna(subset=target_cols, how='all')\n",
    "        print(f\"After target filter: {len(cleaned)} rows (removed {initial_count - len(cleaned)})\")\n",
    "        \n",
    "        # Filter 2: Remove rows with missing core demographics\n",
    "        demo_cols = ['age_category', 'education_level']\n",
    "        available_demo = [col for col in demo_cols if col in cleaned.columns]\n",
    "        if available_demo:\n",
    "            cleaned = cleaned.dropna(subset=available_demo, how='all')\n",
    "            print(f\"After demographics filter: {len(cleaned)} rows\")\n",
    "        \n",
    "        print(f\"Final cleaned dataset: {len(cleaned)} rows, {len(cleaned.columns)} features\")\n",
    "        if missing_cols:\n",
    "            print(f\"Missing columns: {missing_cols}\")\n",
    "            \n",
    "        return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bcc8b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ml_optimized(df):\n",
    "    \"\"\"Transform Lorin data into ML-ready features with consistent categorization\"\"\"\n",
    "    \n",
    "    ml_df = pd.DataFrame()\n",
    "    scaler = StandardScaler()\n",
    "    print(f\"Creating ML features from {len(df)} rows...\")\n",
    "    \n",
    "    # ===================================================================\n",
    "    # 1. DEMOGRAPHICS (5 features) - Consistent with Wash/Oliver\n",
    "    # ===================================================================\n",
    "    \n",
    "    # Age categories (consistent mapping: 1=youngest, 5=oldest)\n",
    "    age_map = {\n",
    "        '18-25': 1, '26-35': 2, '36-45': 3, \n",
    "        '46-55': 4, '56-65': 5, '66-75': 5, '>75': 5\n",
    "    }\n",
    "    ml_df['age_category'] = df['age_category'].map(age_map).fillna(3)\n",
    "    \n",
    "    # Education level (consistent 4-tier system): 1=Low, 2=Medium-Low, 3=Medium-High, 4=High\n",
    "    education_map = {\n",
    "        'No formal qualifications': 1,\n",
    "        'Primary school': 1,\n",
    "        'Secondary school': 2,\n",
    "        'College': 2,\n",
    "        'Technical degree': 3,\n",
    "        'Undergraduate degree': 3,\n",
    "        'Postgraduate degree': 4,\n",
    "        'Doctoral degree': 4\n",
    "    }\n",
    "    ml_df['education_level'] = df['education_level'].map(education_map).fillna(2)\n",
    "    \n",
    "    # IT experience level (ordinal: 1=None to 4=Expert)\n",
    "    it_map = {\n",
    "        'No experience': 1,\n",
    "        'Little experience': 2, \n",
    "        'Some experience': 3,\n",
    "        'Experienced': 4\n",
    "    }\n",
    "    ml_df['it_experience'] = df['it_experience'].map(it_map).fillna(2)\n",
    "    \n",
    "    # Email frequency (ordinal: 1=Rarely to 5=Very frequently)\n",
    "    email_map = {\n",
    "        'Never': 1, 'Rarely': 2, 'Sometimes': 3, \n",
    "        'Often': 4, 'Very often': 5\n",
    "    }\n",
    "    ml_df['email_frequency'] = df['email_frequency'].map(email_map).fillna(3)\n",
    "    \n",
    "    # Security training prior (binary)\n",
    "    training_map = {'Yes': 1, 'No': 0}\n",
    "    ml_df['security_training_prior'] = df['security_training_prior'].map(training_map).fillna(0)\n",
    "    \n",
    "    # ===================================================================\n",
    "    # 2. BIG FIVE PERSONALITY TRAITS (5 features)\n",
    "    # ===================================================================\n",
    "    \n",
    "    personality_fields = [\n",
    "        'personality_extraversion', 'personality_agreeableness',\n",
    "        'personality_conscientiousness', 'personality_neuroticism', 'personality_openness'\n",
    "    ]\n",
    "    \n",
    "    for field in personality_fields:\n",
    "        if field in df.columns:\n",
    "            values = df[field].fillna(df[field].mean())\n",
    "            ml_df[field] = scaler.fit_transform(values.values.reshape(-1, 1)).flatten()\n",
    "        else:\n",
    "            ml_df[field] = 0.0\n",
    "    \n",
    "    # ===================================================================\n",
    "    # 3. PRE-TRAINING SECURITY ATTITUDES (5 features)\n",
    "    # ===================================================================\n",
    "    \n",
    "    security_attitude_fields = [\n",
    "        'pre_security_engagement', 'pre_security_attentiveness',\n",
    "        'pre_security_resistance', 'pre_security_concern', 'pre_security_attitude_total'\n",
    "    ]\n",
    "    \n",
    "    for field in security_attitude_fields:\n",
    "        if field in df.columns:\n",
    "            values = df[field].fillna(df[field].mean())\n",
    "            ml_df[field] = scaler.fit_transform(values.values.reshape(-1, 1)).flatten()\n",
    "        else:\n",
    "            ml_df[field] = 0.0\n",
    "    \n",
    "    # ===================================================================\n",
    "    # 4. BASELINE CAPABILITIES (2 features) - Standardized\n",
    "    # ===================================================================\n",
    "    \n",
    "    capability_fields = ['knowledge_total', 'proficiency']\n",
    "    \n",
    "    for field in capability_fields:\n",
    "        if field in df.columns:\n",
    "            values = df[field].fillna(df[field].mean())\n",
    "            ml_df[field] = scaler.fit_transform(values.values.reshape(-1, 1)).flatten()\n",
    "        else:\n",
    "            ml_df[field] = 0.0\n",
    "    \n",
    "    # ===================================================================\n",
    "    # 5. TARGET VARIABLES (2 features)\n",
    "    # ===================================================================\n",
    "    \n",
    "    target_fields = ['class_phish_accuracy', 'class_nophish_accuracy']\n",
    "    \n",
    "    for field in target_fields:\n",
    "        if field in df.columns:\n",
    "            ml_df[field] = df[field].fillna(df[field].mean())\n",
    "        else:\n",
    "            ml_df[field] = 0.5  # Default to 50% accuracy\n",
    "    \n",
    "    # Convert all to numeric and fill NaN\n",
    "    for col in ml_df.columns:\n",
    "        ml_df[col] = pd.to_numeric(ml_df[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    print(f\"ML features: {len(ml_df)} rows, {len(ml_df.columns)} features\")\n",
    "    return ml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b0e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_column_suffixes(df, suffixes=['_encoded', '_binary', '_standardized']):\n",
    "    \"\"\"Remove specified suffixes from column names for cleaner output\"\"\"\n",
    "    new_columns = {}\n",
    "    for col in df.columns:\n",
    "        new_col = col\n",
    "        for suffix in suffixes:\n",
    "            if col.endswith(suffix):\n",
    "                new_col = col.replace(suffix, '')\n",
    "                break\n",
    "        new_columns[col] = new_col\n",
    "    return df.rename(columns=new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e64c6e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LORIN 2025 PROCESSOR - PERSONALITY-BASED CAPABILITY PREDICTOR\n",
      "============================================================\n",
      "Processing Lorin 2025 Dataset...\n",
      "Raw data: 342 rows, 267 columns\n",
      "After target filter: 342 rows (removed 0)\n",
      "After demographics filter: 342 rows\n",
      "Final cleaned dataset: 342 rows, 19 features\n",
      "Creating ML features from 342 rows...\n",
      "ML features: 342 rows, 19 features\n",
      "\n",
      "Cleaned dataset: 342 rows, 19 columns\n",
      "ML dataset: 342 rows, 19 features\n",
      "Saved to: data/cleaned_data and data/features\n",
      "\n",
      "Training models with 17 features, 342 samples\n",
      "\n",
      "=== Training class_phish_accuracy ===\n",
      "class_phish_accuracy | RF | R2=0.0648\n",
      "class_phish_accuracy | RIDGE | R2=0.1592\n",
      "Test R²: 0.1045, RMSE: 0.2175\n",
      "\n",
      "=== Training class_nophish_accuracy ===\n",
      "class_nophish_accuracy | RF | R2=-0.1231\n",
      "class_nophish_accuracy | RIDGE | R2=-0.0009\n",
      "Test R²: 0.1137, RMSE: 0.1714\n",
      "\n",
      "=== FEATURE IMPORTANCES ===\n",
      "\n",
      "--- class_phish_accuracy ---\n",
      "                          feature  coefficient\n",
      "16                    proficiency     0.106795\n",
      "0                    age_category     0.030045\n",
      "15                knowledge_total     0.026690\n",
      "7   personality_conscientiousness     0.021515\n",
      "9            personality_openness     0.020465\n",
      "8         personality_neuroticism     0.017307\n",
      "1                 education_level     0.013356\n",
      "5        personality_extraversion     0.010185\n",
      "6       personality_agreeableness     0.009518\n",
      "2                   it_experience     0.000000\n",
      "\n",
      "--- class_nophish_accuracy ---\n",
      "                          feature  coefficient\n",
      "16                    proficiency     0.056672\n",
      "1                 education_level     0.031303\n",
      "15                knowledge_total     0.019396\n",
      "7   personality_conscientiousness     0.019349\n",
      "5        personality_extraversion     0.009623\n",
      "8         personality_neuroticism     0.007605\n",
      "9            personality_openness     0.004326\n",
      "0                    age_category     0.000381\n",
      "6       personality_agreeableness     0.000123\n",
      "4         security_training_prior     0.000000\n",
      "\n",
      "All models and predictor saved to: models\n"
     ]
    }
   ],
   "source": [
    "# === MAIN PROCESSING ===\n",
    "print(\"=\" * 60)\n",
    "print(\"LORIN 2025 PROCESSOR - PERSONALITY-BASED CAPABILITY PREDICTOR\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Process data\n",
    "lorin_cleaned = Lorin2025Processor.process()\n",
    "lorin_ml = create_ml_optimized(lorin_cleaned)\n",
    "\n",
    "# Save datasets\n",
    "lorin_cleaned.to_csv(CLEANED_DATA_DIR / \"lorin_2025_cleaned.csv\", index=False)\n",
    "lorin_ml_clean = remove_column_suffixes(lorin_ml)\n",
    "lorin_ml_clean.to_csv(FEATURES_DIR / \"lorin_2025_ml_optimized.csv\", index=False)\n",
    "\n",
    "print(f\"\\nCleaned dataset: {len(lorin_cleaned)} rows, {len(lorin_cleaned.columns)} columns\")\n",
    "print(f\"ML dataset: {len(lorin_ml)} rows, {len(lorin_ml.columns)} features\")\n",
    "print(f\"Saved to: {CLEANED_DATA_DIR} and {FEATURES_DIR}\")\n",
    "\n",
    "# === MODEL TRAINING ===\n",
    "def train_model(X, y, task='regression', name=''):\n",
    "    \"\"\"Train and evaluate models with cross-validation\"\"\"\n",
    "    \n",
    "    if task == 'classification':\n",
    "        models = {\n",
    "            'rf': RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', random_state=42),\n",
    "            'lr': Pipeline([('scaler', StandardScaler()), \n",
    "                           ('model', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42))])\n",
    "        }\n",
    "        scoring = 'accuracy'\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        models = {\n",
    "            'rf': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
    "            'ridge': Pipeline([('scaler', StandardScaler()), ('model', Ridge(random_state=42))])\n",
    "        }\n",
    "        scoring = 'r2'\n",
    "        cv = 5\n",
    "    \n",
    "    best_model, best_score, best_name = None, -np.inf, None\n",
    "    \n",
    "    for k, model in models.items():\n",
    "        scores = cross_val_score(model, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "        mean_score = scores.mean()\n",
    "        print(f\"{name} | {k.upper()} | {scoring.upper()}={mean_score:.4f}\")\n",
    "        \n",
    "        if mean_score > best_score:\n",
    "            best_model, best_score, best_name = model, mean_score, k\n",
    "    \n",
    "    # Final evaluation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y if task=='classification' else None, test_size=0.2, random_state=42)\n",
    "    \n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    if task == 'classification':\n",
    "        print(f\"Test Accuracy: {accuracy_score(y_test, yd):.4f}\")\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    else:\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"Test R²: {r2:.4f}, RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    return best_model, best_score, best_name\n",
    "\n",
    "def show_feature_importance(model, feature_names, target_name, top_n=10):\n",
    "    \"\"\"Display top feature importances\"\"\"\n",
    "    print(f\"\\n--- {target_name} ---\")\n",
    "    \n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        importances = model.feature_importances_\n",
    "        fi_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importances\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        print(fi_df.head(top_n))\n",
    "        \n",
    "    elif isinstance(model, Pipeline) and hasattr(model.named_steps['model'], 'coef_'):\n",
    "        coefs = np.abs(model.named_steps['model'].coef_.flatten())\n",
    "        fi_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'coefficient': coefs\n",
    "        }).sort_values('coefficient', ascending=False)\n",
    "        print(fi_df.head(top_n))\n",
    "\n",
    "# === MODEL TRAINING ===\n",
    "\n",
    "# Define features (X) and targets (Y) based on specification\n",
    "X_features = [\n",
    "    # Demographics (5)\n",
    "    'age_category', 'education_level', 'it_experience', 'email_frequency', 'security_training_prior',\n",
    "    \n",
    "    # Big Five Personality (5)\n",
    "    'personality_extraversion', 'personality_agreeableness', 'personality_conscientiousness',\n",
    "    'personality_neuroticism', 'personality_openness',\n",
    "    \n",
    "    # Pre-Training Security Attitudes (5) \n",
    "    'pre_security_engagement', 'pre_security_attentiveness', 'pre_security_resistance',\n",
    "    'pre_security_concern', 'pre_security_attitude_total',\n",
    "    \n",
    "    # Baseline Capabilities (2)\n",
    "    'knowledge_total', 'proficiency'\n",
    "]\n",
    "\n",
    "# Targets: Pre-training phishing detection capabilities\n",
    "y_targets = ['class_phish_accuracy', 'class_nophish_accuracy']\n",
    "\n",
    "# Prepare features\n",
    "X = lorin_ml[X_features].fillna(0)\n",
    "print(f\"\\nTraining models with {X.shape[1]} features, {X.shape[0]} samples\")\n",
    "\n",
    "# Train models\n",
    "trained_models = {}\n",
    "model_info = {}\n",
    "\n",
    "for target in y_targets:\n",
    "    if target in lorin_ml.columns and lorin_ml[target].nunique() > 1:\n",
    "        y = lorin_ml[target].fillna(0)\n",
    "        print(f\"\\n=== Training {target} ===\")\n",
    "        \n",
    "        # Both targets are continuous accuracy scores (0-1), so use regression\n",
    "        model, score, name = train_model(X, y, 'regression', target)\n",
    "        model_info[target] = {'type': 'regression', 'model': name, 'score': score}\n",
    "        \n",
    "        trained_models[target] = model\n",
    "\n",
    "# Show feature importances\n",
    "print(\"\\n=== FEATURE IMPORTANCES ===\")\n",
    "for target, model in trained_models.items():\n",
    "    show_feature_importance(model, X_features, target)\n",
    "\n",
    "# Save models individually\n",
    "for name, model in trained_models.items():\n",
    "    joblib.dump(model, MODELS_DIR / f\"lorin_{name}_model.joblib\")\n",
    "\n",
    "# Save metadata\n",
    "joblib.dump({\n",
    "    'features': X_features, \n",
    "    'models': model_info,\n",
    "    'feature_count': len(X_features)\n",
    "}, MODELS_DIR / \"lorin_metadata.joblib\")\n",
    "\n",
    "# Create prediction class\n",
    "class LorinPredictor:\n",
    "    def __init__(self, models, features):\n",
    "        self.models = models\n",
    "        self.features = features\n",
    "        self.model_info = model_info\n",
    "    \n",
    "    def __call__(self, input_data):\n",
    "        if isinstance(input_data, dict):\n",
    "            input_data = pd.DataFrame([input_data])\n",
    "        \n",
    "        # Ensure all features present\n",
    "        for f in self.features:\n",
    "            if f not in input_data.columns:\n",
    "                input_data[f] = 0\n",
    "        \n",
    "        input_data = input_data[self.features].fillna(0)\n",
    "        \n",
    "        predictions = {}\n",
    "        for target, model in self.models.items():\n",
    "            pred = model.predict(input_data)\n",
    "            # All Lorin targets are regression (continuous accuracy scores)\n",
    "            predictions[target] = {'prediction': float(pred[0])}\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# Save predictor\n",
    "lorin_predictor = LorinPredictor(trained_models, X_features)\n",
    "joblib.dump(lorin_predictor, MODELS_DIR / \"lorin_predictor.joblib\")\n",
    "\n",
    "print(f\"\\nAll models and predictor saved to: {MODELS_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cypersona",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
