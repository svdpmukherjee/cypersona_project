{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f8ce1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f92d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths\n",
    "RAW_DATA_DIR = Path(\"data/raw_data\")\n",
    "CLEANED_DATA_DIR = Path(\"data/cleaned_data\")\n",
    "FEATURES_DIR = Path(\"data/features\")\n",
    "MODELS_DIR = Path(\"models\")\n",
    "\n",
    "for path in [CLEANED_DATA_DIR, FEATURES_DIR, MODELS_DIR]:\n",
    "    path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728bfda5",
   "metadata": {},
   "source": [
    "## OLIVER et al. (2022) Dataset Processing\n",
    "### Step 1: Cleaning with renaming readable feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "175afbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Oliver2022Processor:\n",
    "    @staticmethod\n",
    "    def process():\n",
    "        print(\"Processing Oliver 2022 Dataset...\")\n",
    "        \n",
    "        # Try different encodings\n",
    "        for encoding in ['utf-8', 'cp1252', 'iso-8859-1', 'latin1']:\n",
    "            try:\n",
    "                df = pd.read_csv(RAW_DATA_DIR / \"phishing_oliver_2022.csv\", encoding=encoding)\n",
    "                print(f\"Loaded with {encoding} encoding: {len(df)} rows, {len(df.columns)} columns\")\n",
    "                break\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "        \n",
    "        # Feature mapping\n",
    "        features = {\n",
    "            # Demographics\n",
    "            'age': 'DE02_01',\n",
    "            'gender': 'Sex',\n",
    "            'education_level': 'Edu1',\n",
    "            'employment_status': 'Job',\n",
    "            'employment_type': 'Anstllung',\n",
    "            \n",
    "            # IT Background\n",
    "            'it_job_status': 'ITSJOB',\n",
    "            'phishing_victim_count': 'Phish_Vic_Count',\n",
    "            \n",
    "            # PMT Constructs\n",
    "            'perceived_knowledge': 'Per_Know',\n",
    "            'perceived_self_efficacy': 'Per_SE',\n",
    "            'perceived_severity': 'Per_Sev',\n",
    "            'perceived_vulnerability': 'Per_Vuln',\n",
    "            'email_trust': 'E_Trust',\n",
    "            \n",
    "            # Performance Measures\n",
    "            'knowledge_test_percent_correct': 'correct_percent_kt',\n",
    "            'phishing_test_percent_correct': 'correct_percent_pt',\n",
    "            'knowledge_test_total_correct': 'correct_total_kt',\n",
    "            'phishing_test_total_correct': 'correct_total_pt',\n",
    "        }\n",
    "        \n",
    "        # Create cleaned dataframe\n",
    "        cleaned = pd.DataFrame()\n",
    "        for new_col, old_col in features.items():\n",
    "            if old_col in df.columns:\n",
    "                cleaned[new_col] = df[old_col]\n",
    "            else:\n",
    "                cleaned[new_col] = np.nan\n",
    "        \n",
    "        # Data quality filters\n",
    "        initial_count = len(cleaned)\n",
    "        cleaned = cleaned.dropna(subset=['age', 'gender'], how='any')\n",
    "        performance_cols = ['knowledge_test_percent_correct', 'phishing_test_percent_correct']\n",
    "        cleaned = cleaned.dropna(subset=performance_cols, how='all')\n",
    "        \n",
    "        print(f\"After filtering: {len(cleaned)} rows (removed {initial_count - len(cleaned)})\")\n",
    "        return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea575d22",
   "metadata": {},
   "source": [
    "### Step 2. Feature Engineering\n",
    "\n",
    "##### **Purpose**: Extract competence assessment patterns from Protection Motivation Theory data\n",
    "\n",
    "##### **Unique Value**: Controlled assessments measuring performance-perception gaps in phishing detection\n",
    "##### **Research Questions Enabled**:\n",
    "1. How WELL can someone detect phishing vs. how confident they feel?\n",
    "2. What psychological factors predict actual phishing detection accuracy? \n",
    "3. Can we identify overconfidence patterns in cybersecurity skills?\n",
    "4. Which PMT constructs best predict objective performance?\n",
    "\n",
    "#### **X_inputs**:\n",
    "1. **Demographics (4)**: Age categories, gender, education level, employment status\n",
    "2. **IT Background (3)**: IT job frequency, previous phishing victimization (binary + count)  \n",
    "3. **PMT Psychological Constructs (5)**: Perceived knowledge, self-efficacy, severity, vulnerability, email trust\n",
    "\n",
    "#### **Y_targets**:\n",
    "1. **Primary**: Phishing detection accuracy (0-100%) - objective performance measure\n",
    "2. **Secondary**: Security knowledge test accuracy (0-100%) - foundational knowledge measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faa97978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ml_optimized(df):\n",
    "    \"\"\"Transform Oliver data into ML-ready features\"\"\"\n",
    "    \n",
    "    ml_df = pd.DataFrame()\n",
    "    scaler = StandardScaler()\n",
    "    print(f\"Creating ML features from {len(df)} rows...\")\n",
    "    \n",
    "    # Demographics (5 features) - Consistent with Wash categories\n",
    "    # Age categories (same as Wash)\n",
    "    age_bins = [0, 25, 35, 55, 75, 100]\n",
    "    age_labels = [1, 2, 3, 4, 5]  # 1=youngest, 5=oldest\n",
    "    ml_df['age_category'] = pd.cut(df['age'], bins=age_bins, labels=age_labels, include_lowest=True).fillna(3)\n",
    "    \n",
    "    # Gender (binary: 1=Male, 0=Female)\n",
    "    gender_map = {1: 0, 2: 1}  # Male=1, Female=0 \n",
    "    ml_df['gender'] = df['gender'].map(gender_map).fillna(0)\n",
    "    \n",
    "    # Education level\n",
    "    # 1=Dropped out, 3=Elementary, 4=Secondary, 5=Apprenticeship, 6=Vocational, 7=A-levels, 8=College/University, 9=Still in school, 10=Other\n",
    "    education_map = {\n",
    "        1: 1, 9: 1,  # Low: Dropped out, Still in school\n",
    "        3: 2, 4: 2,  # Medium-Low: Elementary, Secondary  \n",
    "        5: 3, 6: 3, 7: 3,  # Medium-High: Apprenticeship, Vocational, A-levels\n",
    "        8: 4,  # High: College/University\n",
    "        10: 2  # Other -> Medium-Low\n",
    "    }\n",
    "    ml_df['education_level'] = df['education_level'].map(education_map).fillna(2)\n",
    "    \n",
    "    # Employment Status (binary: employed=1, unemployed=0, based on employment_type)\n",
    "    # 1=High Schooler, 2=Apprenticeship, 3=Student, 4=Employee, 5=Public Servant, 6=Self-Employed, 7=Unemployed, 8=Other\n",
    "    employment_map = {\n",
    "        1: 0, 3: 0, 7: 0,  # Not working: High schooler, Student, Unemployed\n",
    "        2: 0,  # Training: Apprenticeship\n",
    "        4: 1, 5: 1,  # Employee: Employee, Public servant\n",
    "        6: 1,  # Self-employed\n",
    "        8: 0  # Other -> Not working\n",
    "    }\n",
    "    ml_df['employment_status'] = df['employment_type'].map(employment_map).fillna(0)\n",
    "    \n",
    "    # IT Background (3 features)\n",
    "    it_job_map = {1: 1, 2: 1, 3: 1, 4: 0, 5: 0}  # Regular IT work vs Little/None\n",
    "    ml_df['it_job'] = df['it_job_status'].map(it_job_map).fillna(0)\n",
    "    ml_df['phishing_victim'] = (df['phishing_victim_count'] > 0).astype(int)\n",
    "    \n",
    "    # Standardized victim count\n",
    "    victim_counts = df['phishing_victim_count'].fillna(0)\n",
    "    ml_df['phishing_victim_count'] = scaler.fit_transform(victim_counts.values.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # PMT Constructs (5 features) - Standardized\n",
    "    pmt_fields = ['perceived_knowledge', 'perceived_self_efficacy', 'perceived_severity', \n",
    "                  'perceived_vulnerability', 'email_trust']\n",
    "    \n",
    "    for field in pmt_fields:\n",
    "        if field in df.columns:\n",
    "            values = df[field].fillna(df[field].mean())\n",
    "            ml_df[field] = scaler.fit_transform(values.values.reshape(-1, 1)).flatten()\n",
    "        else:\n",
    "            ml_df[field] = 0.0\n",
    "    \n",
    "    # Performance Measures (4 features) - Standardized\n",
    "    performance_fields = ['knowledge_test_percent_correct', 'phishing_test_percent_correct']\n",
    "    \n",
    "    for field in performance_fields:\n",
    "        if field in df.columns:\n",
    "            values = df[field].fillna(df[field].mean())\n",
    "            ml_df[field] = scaler.fit_transform(values.values.reshape(-1, 1)).flatten()\n",
    "        else:\n",
    "            ml_df[field] = 0.0\n",
    "    \n",
    "    # Convert all to float and fill NaN\n",
    "    for col in ml_df.columns:\n",
    "        ml_df[col] = pd.to_numeric(ml_df[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    print(f\"ML features: {len(ml_df)} rows, {len(ml_df.columns)} features\")\n",
    "    return ml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "849373ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_column_suffixes(df, suffixes=['_encoded', '_binary', '_standardized']):\n",
    "    \"\"\"Remove specified suffixes from column names for cleaner output\"\"\"\n",
    "    new_columns = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        new_col = col\n",
    "        for suffix in suffixes:\n",
    "            if col.endswith(suffix):\n",
    "                new_col = col.replace(suffix, '')\n",
    "                break\n",
    "        new_columns[col] = new_col\n",
    "    \n",
    "    return df.rename(columns=new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6973642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MODEL TRAINING ===\n",
    "def train_model(X, y, task='classification', name=''):\n",
    "    \"\"\"Train and evaluate models with cross-validation\"\"\"\n",
    "    \n",
    "    if task == 'classification':\n",
    "        models = {\n",
    "            'rf': RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', random_state=42),\n",
    "            'lr': Pipeline([('scaler', StandardScaler()), \n",
    "                           ('model', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42))])\n",
    "        }\n",
    "        scoring = 'accuracy'\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        models = {\n",
    "            'rf': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
    "            'ridge': Pipeline([('scaler', StandardScaler()), ('model', Ridge(random_state=42))])\n",
    "        }\n",
    "        scoring = 'r2'\n",
    "        cv = 5\n",
    "    \n",
    "    best_model, best_score, best_name = None, -np.inf, None\n",
    "    \n",
    "    for k, model in models.items():\n",
    "        scores = cross_val_score(model, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "        mean_score = scores.mean()\n",
    "        print(f\"{name} | {k.upper()} | {scoring.upper()}={mean_score:.4f}\")\n",
    "        \n",
    "        if mean_score > best_score:\n",
    "            best_model, best_score, best_name = model, mean_score, k\n",
    "    \n",
    "    # Final evaluation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y if task=='classification' else None, test_size=0.2, random_state=42)\n",
    "    \n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    if task == 'classification':\n",
    "        print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    else:\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"Test R²: {r2:.4f}, RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    return best_model, best_score, best_name\n",
    "\n",
    "def show_feature_importance(model, feature_names, target_name, top_n=10):\n",
    "    \"\"\"Display top feature importances\"\"\"\n",
    "    print(f\"\\n--- {target_name} ---\")\n",
    "    \n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        importances = model.feature_importances_\n",
    "        fi_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importances\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        print(fi_df.head(top_n))\n",
    "        \n",
    "    elif isinstance(model, Pipeline) and hasattr(model.named_steps['model'], 'coef_'):\n",
    "        coefs = np.abs(model.named_steps['model'].coef_.flatten())\n",
    "        fi_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'coefficient': coefs\n",
    "        }).sort_values('coefficient', ascending=False)\n",
    "        print(fi_df.head(top_n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5a2188c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Oliver 2022 Dataset...\n",
      "Loaded with cp1252 encoding: 296 rows, 84 columns\n",
      "After filtering: 288 rows (removed 8)\n",
      "Creating ML features from 288 rows...\n",
      "ML features: 288 rows, 14 features\n",
      "\n",
      "Cleaned: 288 rows, 16 columns\n",
      "ML-ready: 288 rows, 14 features\n",
      "\n",
      "Training models with 12 features, 288 samples\n",
      "\n",
      "=== Training phishing_test_percent_correct ===\n",
      "phishing_test_percent_correct | RF | R2=-0.1262\n",
      "phishing_test_percent_correct | RIDGE | R2=-0.0197\n",
      "Test R²: 0.0017, RMSE: 0.9105\n",
      "\n",
      "=== Training knowledge_test_percent_correct ===\n",
      "knowledge_test_percent_correct | RF | R2=0.0518\n",
      "knowledge_test_percent_correct | RIDGE | R2=-0.0115\n",
      "Test R²: -0.2122, RMSE: 1.1029\n",
      "\n",
      "=== FEATURE IMPORTANCES ===\n",
      "\n",
      "--- phishing_test_percent_correct ---\n",
      "                    feature  coefficient\n",
      "0              age_category     0.313414\n",
      "8   perceived_self_efficacy     0.151786\n",
      "2           education_level     0.099393\n",
      "3         employment_status     0.071690\n",
      "10  perceived_vulnerability     0.040978\n",
      "4                    it_job     0.035199\n",
      "9        perceived_severity     0.023235\n",
      "7       perceived_knowledge     0.018477\n",
      "1                    gender     0.006486\n",
      "11              email_trust     0.005907\n",
      "\n",
      "--- knowledge_test_percent_correct ---\n",
      "                    feature  importance\n",
      "10  perceived_vulnerability    0.170044\n",
      "0              age_category    0.144531\n",
      "11              email_trust    0.141816\n",
      "8   perceived_self_efficacy    0.118149\n",
      "7       perceived_knowledge    0.106069\n",
      "1                    gender    0.104969\n",
      "9        perceived_severity    0.070637\n",
      "2           education_level    0.051688\n",
      "4                    it_job    0.036418\n",
      "6     phishing_victim_count    0.036288\n",
      "\n",
      "All models and predictor saved to: models\n"
     ]
    }
   ],
   "source": [
    "# === MAIN PROCESSING ===\n",
    "\n",
    "# Step 1: Clean data\n",
    "oliver_cleaned = Oliver2022Processor.process()\n",
    "oliver_ml = create_ml_optimized(oliver_cleaned)\n",
    "\n",
    "# Step 2: Save datasets\n",
    "oliver_cleaned.to_csv(CLEANED_DATA_DIR / \"oliver_2022_cleaned.csv\", index=False)\n",
    "oliver_ml.to_csv(FEATURES_DIR / \"oliver_2022_ml_optimized.csv\", index=False)\n",
    "\n",
    "print(f\"\\nCleaned: {len(oliver_cleaned)} rows, {len(oliver_cleaned.columns)} columns\")\n",
    "print(f\"ML-ready: {len(oliver_ml)} rows, {len(oliver_ml.columns)} features\")\n",
    "\n",
    "# Step 3: Train models\n",
    "# Define features and targets based on Oliver model requirements\n",
    "X_features = [\n",
    "    'age_category', 'gender', 'education_level', 'employment_status',\n",
    "    'it_job', 'phishing_victim', 'phishing_victim_count',\n",
    "    'perceived_knowledge', 'perceived_self_efficacy', 'perceived_severity', \n",
    "    'perceived_vulnerability', 'email_trust'\n",
    "]\n",
    "\n",
    "# Targets: Performance measures (regression)\n",
    "y_targets = ['phishing_test_percent_correct', 'knowledge_test_percent_correct']\n",
    "\n",
    "# Prepare features\n",
    "X = oliver_ml[X_features].fillna(0)\n",
    "print(f\"\\nTraining models with {X.shape[1]} features, {X.shape[0]} samples\")\n",
    "\n",
    "# Train models\n",
    "trained_models = {}\n",
    "model_info = {}\n",
    "\n",
    "for target in y_targets:\n",
    "    if target in oliver_ml.columns and oliver_ml[target].nunique() > 1:\n",
    "        y = oliver_ml[target].fillna(0)\n",
    "        print(f\"\\n=== Training {target} ===\")\n",
    "        \n",
    "        model, score, name = train_model(X, y, 'regression', target)\n",
    "        trained_models[target] = model\n",
    "        model_info[target] = {'type': 'regression', 'model': name, 'score': score}\n",
    "\n",
    "# Show feature importances\n",
    "print(\"\\n=== FEATURE IMPORTANCES ===\")\n",
    "for target, model in trained_models.items():\n",
    "    show_feature_importance(model, X_features, target)\n",
    "\n",
    "# Save models individually\n",
    "for name, model in trained_models.items():\n",
    "    joblib.dump(model, MODELS_DIR / f\"oliver_{name}_model.joblib\")\n",
    "\n",
    "# Save metadata\n",
    "joblib.dump({\n",
    "    'features': X_features, \n",
    "    'models': model_info,\n",
    "    'feature_count': len(X_features)\n",
    "}, MODELS_DIR / \"oliver_metadata.joblib\")\n",
    "\n",
    "# Create prediction class\n",
    "class OliverPredictor:\n",
    "    def __init__(self, models, features):\n",
    "        self.models = models\n",
    "        self.features = features\n",
    "        self.model_info = model_info\n",
    "    \n",
    "    def __call__(self, input_data):\n",
    "        if isinstance(input_data, dict):\n",
    "            input_data = pd.DataFrame([input_data])\n",
    "        \n",
    "        # Ensure all features present\n",
    "        for f in self.features:\n",
    "            if f not in input_data.columns:\n",
    "                input_data[f] = 0\n",
    "        \n",
    "        input_data = input_data[self.features].fillna(0)\n",
    "        \n",
    "        predictions = {}\n",
    "        for target, model in self.models.items():\n",
    "            pred = model.predict(input_data)\n",
    "            predictions[target] = {'prediction': float(pred[0])}\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# Save predictor\n",
    "oliver_predictor = OliverPredictor(trained_models, X_features)\n",
    "joblib.dump(oliver_predictor, MODELS_DIR / \"oliver_predictor.joblib\")\n",
    "\n",
    "print(f\"\\nAll models and predictor saved to: {MODELS_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cypersona",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
