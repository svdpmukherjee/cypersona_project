{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f8ce1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f92d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths\n",
    "RAW_DATA_DIR = Path(\"data/raw_data\")\n",
    "CLEANED_DATA_DIR = Path(\"data/cleaned_data\")\n",
    "CLEANED_DATA_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728bfda5",
   "metadata": {},
   "source": [
    "#### 1. Oliver 2022 Dataset Processing\n",
    "#### **Purpose**: Extract psychological foundations and signal detection metrics\n",
    "#### **Key Features**: Response bias, signal detection parameters, Protection Motivation Theory constructs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "175afbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Oliver2022Processor:\n",
    "    \"\"\"\n",
    "    Processes Oliver et al. (2022) dataset for comprehensive psychological validation\n",
    "    Includes ALL variables except timing data\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def process():\n",
    "        print(\"Processing Oliver 2022 Dataset - Complete Version...\")\n",
    "        \n",
    "        # Try different encodings to handle special characters\n",
    "        encodings = ['utf-8', 'cp1252', 'iso-8859-1', 'latin1']\n",
    "        df = None\n",
    "        \n",
    "        for encoding in encodings:\n",
    "            try:\n",
    "                df = pd.read_csv(RAW_DATA_DIR / \"phishing_oliver_2022.csv\", encoding=encoding)\n",
    "                print(f\"   Successfully loaded with {encoding} encoding\")\n",
    "                break\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "        \n",
    "        if df is None:\n",
    "            raise Exception(\"Could not read CSV with any standard encoding\")\n",
    "            \n",
    "        print(f\"   Raw data: {len(df)} rows, {len(df.columns)} columns\")\n",
    "        \n",
    "        # Complete feature mapping - ALL columns except timing\n",
    "        features = {\n",
    "            # === PARTICIPANT IDENTIFIERS ===\n",
    "            'participant_case_id': 'CASE',  # int: Unique participant identifier\n",
    "            'reference_code': 'REF',  # str: Study reference code\n",
    "            'completion_code': 'CO01',  # int: Survey completion code\n",
    "            \n",
    "            # === PRIMARY PERFORMANCE OUTCOMES ===\n",
    "            'phishing_test_total_correct': 'correct_total_pt',  # int: Raw phishing test score\n",
    "            'phishing_test_percent_correct': 'correct_percent_pt',  # num: 0-1 phishing test accuracy - CRITICAL\n",
    "            'knowledge_test_total_correct': 'correct_total_kt',  # int: Raw knowledge test score\n",
    "            'knowledge_test_percent_correct': 'correct_percent_kt',  # num: 0-1 knowledge accuracy\n",
    "            \n",
    "            # === PROTECTION MOTIVATION THEORY COMPOSITES ===\n",
    "            'perceived_knowledge': 'Per_Know',  # num: Self-assessed phishing knowledge - KEY\n",
    "            'email_trust': 'E_Trust',  # num: Trust in email communications - CRITICAL for personas\n",
    "            'perceived_severity': 'Per_Sev',  # num: Perceived severity of phishing threats\n",
    "            'perceived_self_efficacy': 'Per_SE',  # num: Confidence in detection ability - KEY calibration\n",
    "            'perceived_vulnerability': 'Per_Vuln',  # num: Personal vulnerability perception\n",
    "            \n",
    "            # === DEMOGRAPHICS ===\n",
    "            'participant_gender': 'Sex',  # int: 1=male, 2=female\n",
    "            'participant_age': 'DE02_01',  # num: Age in years\n",
    "            'education_level': 'Edu1',  # int: Educational attainment level\n",
    "            'education_other': 'Edu_other',  # str: Custom education description\n",
    "            'job_category': 'Job',  # int: Employment/occupation category\n",
    "            'job_other': 'Job_othr',  # str: Custom job description\n",
    "            'employment_type': 'Anstllung',  # int: Type of employment arrangement\n",
    "            'employment_other': 'Anst_offen',  # str: Custom employment type\n",
    "            \n",
    "            # === IT BACKGROUND ===\n",
    "            'works_in_it': 'ITSJOB',  # int: Whether participant works in IT field\n",
    "            'phishing_victim_count': 'Phish_Vic_Count',  # int: Times fallen for phishing - KEY modifier\n",
    "            \n",
    "            # === PERCEIVED KNOWLEDGE ITEMS ===\n",
    "            'pk_item_1': 'PK1',  # int: \"I know what phishing is\"\n",
    "            'pk_item_2': 'PK2',  # int: \"I understand phishing techniques\"\n",
    "            \n",
    "            # === EMAIL TRUST ITEMS ===\n",
    "            'et_item_1': 'ET1',  # int: Trust in email sender authenticity\n",
    "            'et_item_2': 'ET2',  # int: Trust in email content reliability\n",
    "            'et_item_3': 'ET3',  # int: General trust in email communications\n",
    "            \n",
    "            # === PERCEIVED SEVERITY ITEMS ===\n",
    "            'ps_item_1': 'PS1',  # int: Severity of phishing consequences\n",
    "            'ps_item_2': 'PS2',  # int: Impact of falling for phishing\n",
    "            'ps_item_3': 'PS3',  # int: Seriousness of phishing threats\n",
    "            \n",
    "            # === PERCEIVED VULNERABILITY ITEMS ===\n",
    "            'pv_item_1': 'PV1',  # int: Personal risk of phishing attacks\n",
    "            'pv_item_2': 'PV2',  # int: Likelihood of being targeted\n",
    "            'pv_item_3': 'PV3',  # int: Susceptibility to phishing\n",
    "            \n",
    "            # === SELF-EFFICACY ITEMS ===\n",
    "            'se_item_1': 'SE1',  # int: Confidence in detecting phishing\n",
    "            'se_item_2': 'SE2',  # int: Ability to avoid phishing scams\n",
    "            'se_item_3': 'SE3',  # int: Skills in phishing recognition\n",
    "            \n",
    "            # === KNOWLEDGE TEST ITEMS (with answer keys) ===\n",
    "            'knowledge_q1': 'KT01',  # int: Knowledge question 1 (correct=2)\n",
    "            'knowledge_q2': 'KT02',  # int: Knowledge question 2 (correct=2)\n",
    "            'knowledge_q5': 'KT05',  # int: Knowledge question 5 (correct=2)\n",
    "            'knowledge_q7': 'KT07',  # int: Knowledge question 7 (correct=2)\n",
    "            'knowledge_q9': 'KT09',  # int: Knowledge question 9 (correct=2)\n",
    "            'knowledge_q10': 'KT10',  # int: Knowledge question 10 (correct=2)\n",
    "            'knowledge_q14': 'KT14',  # int: Knowledge question 14 (correct=2)\n",
    "            'knowledge_q15': 'KT15',  # int: Knowledge question 15 (correct=2)\n",
    "            'knowledge_q16': 'KT16',  # int: Knowledge question 16 (correct=1)\n",
    "            'knowledge_q17': 'KT17',  # int: Knowledge question 17 (correct=1)\n",
    "            \n",
    "            # === PHISHING TEST ITEMS - CRITICAL FOR SIGNAL DETECTION ===\n",
    "            # Phishing emails (correct response = 2 \"phishing\")\n",
    "            'phishing_email_5': 'PTP5',  # int: Email 5 classification (should be 2)\n",
    "            'phishing_email_6': 'PTP6',  # int: Email 6 classification (should be 2)\n",
    "            'phishing_email_9': 'PTP9',  # int: Email 9 classification (should be 2)\n",
    "            'phishing_email_10': 'PTP10',  # int: Email 10 classification (should be 2)\n",
    "            \n",
    "            # Legitimate emails (correct response = 1 \"legitimate\")\n",
    "            'legitimate_email_4': 'PTE4',  # int: Email 4 classification (should be 1)\n",
    "            'legitimate_email_5': 'PTE5',  # int: Email 5 classification (should be 1)\n",
    "            'legitimate_email_7': 'PTE7',  # int: Email 7 classification (should be 1)\n",
    "            'legitimate_email_10': 'PTE10',  # int: Email 10 classification (should be 1)\n",
    "            \n",
    "            # === SURVEY ADMINISTRATION ===\n",
    "            'last_page_viewed': 'LASTPAGE',  # int: Final page participant reached\n",
    "            'max_pages': 'MAXPAGE',  # int: Total pages in survey\n",
    "            'survey_quality_flag': 'DEG_TIME'  # int: Survey completion quality metric\n",
    "        }\n",
    "        \n",
    "        # Create cleaned dataframe\n",
    "        cleaned = pd.DataFrame()\n",
    "        missing_cols = []\n",
    "        \n",
    "        for new_col, old_col in features.items():\n",
    "            if old_col in df.columns:\n",
    "                cleaned[new_col] = df[old_col]\n",
    "            else:\n",
    "                print(f\"Warning: Column '{old_col}' not found, setting '{new_col}' to NaN\")\n",
    "                cleaned[new_col] = np.nan\n",
    "                missing_cols.append(old_col)\n",
    "        \n",
    "        # Remove timing columns (TIME001-TIME024, TIME_SUM)\n",
    "        timing_cols = [col for col in df.columns if col.startswith('TIME')]\n",
    "        if timing_cols:\n",
    "            print(f\"Removed {len(timing_cols)} timing columns for persona generation\")\n",
    "        \n",
    "        # Data cleaning and transformations\n",
    "        # Convert gender properly (1=male, 2=female)\n",
    "        if 'participant_gender' in cleaned.columns:\n",
    "            cleaned['participant_gender'] = cleaned['participant_gender'].map({\n",
    "                1: 'Male', \n",
    "                2: 'Female'\n",
    "            })\n",
    "        \n",
    "        # Calculate Signal Detection Theory metrics from individual responses\n",
    "        cleaned = Oliver2022Processor._calculate_sdt_metrics(cleaned)\n",
    "        \n",
    "        print(f\"Processed: {len(cleaned)} rows, {len(cleaned.columns)} features\")\n",
    "        if missing_cols:\n",
    "            print(f\"Missing columns: {missing_cols}\")\n",
    "            \n",
    "        return cleaned\n",
    "    \n",
    "    @staticmethod\n",
    "    def _calculate_sdt_metrics(df):\n",
    "        \"\"\"Calculate Signal Detection Theory metrics from individual email responses\"\"\"\n",
    "        \n",
    "        # Phishing email columns (correct = 2)\n",
    "        phishing_cols = ['phishing_email_5', 'phishing_email_6', 'phishing_email_9', 'phishing_email_10']\n",
    "        # Legitimate email columns (correct = 1) \n",
    "        legitimate_cols = ['legitimate_email_4', 'legitimate_email_5', 'legitimate_email_7', 'legitimate_email_10']\n",
    "        \n",
    "        # Calculate hits and misses for phishing emails\n",
    "        df['hits'] = df[phishing_cols].apply(lambda row: sum(row == 2), axis=1)\n",
    "        df['misses'] = df[phishing_cols].apply(lambda row: sum(row == 1), axis=1)\n",
    "        \n",
    "        # Calculate false alarms and correct rejections for legitimate emails\n",
    "        df['false_alarms'] = df[legitimate_cols].apply(lambda row: sum(row == 2), axis=1)\n",
    "        df['correct_rejections'] = df[legitimate_cols].apply(lambda row: sum(row == 1), axis=1)\n",
    "        \n",
    "        # Convert to rates (divide by 4 since there are 4 of each type)\n",
    "        df['hit_rate'] = df['hits'] / 4\n",
    "        df['miss_rate'] = df['misses'] / 4  \n",
    "        df['false_alarm_rate'] = df['false_alarms'] / 4\n",
    "        df['correct_rejection_rate'] = df['correct_rejections'] / 4\n",
    "        \n",
    "        # Calculate bias and sensitivity measures\n",
    "        df['response_bias'] = df['hit_rate'] - df['correct_rejection_rate']  # Liberal vs Conservative\n",
    "        df['sensitivity'] = df['hit_rate'] - df['false_alarm_rate']  # Discrimination ability\n",
    "        \n",
    "        # Add interpretive flags\n",
    "        df['bias_tendency'] = df['response_bias'].apply(lambda x: \n",
    "            'Liberal' if x > 0.1 else 'Conservative' if x < -0.1 else 'Neutral')\n",
    "        df['detection_ability'] = df['sensitivity'].apply(lambda x:\n",
    "            'High' if x > 0.5 else 'Low' if x < 0.2 else 'Medium')\n",
    "        \n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e78f2029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Oliver 2022 Dataset - Complete Version...\n",
      "   Successfully loaded with cp1252 encoding\n",
      "   Raw data: 296 rows, 84 columns\n",
      "Removed 25 timing columns for persona generation\n",
      "Processed: 296 rows, 69 features\n",
      "Saved complete dataset to: data/cleaned_data/oliver_2022_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "oliver2022_data = Oliver2022Processor.process()\n",
    "oliver2022_data.to_csv(CLEANED_DATA_DIR / \"oliver_2022_cleaned.csv\", index=False)\n",
    "print(f\"Saved complete dataset to: {CLEANED_DATA_DIR / 'oliver_2022_cleaned.csv'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cypersona",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
